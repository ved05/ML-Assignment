{"cells":[{"cell_type":"markdown","metadata":{"run_control":{"marked":true},"id":"w_42xh3ofCpI"},"source":["# Introduction to Machine Learning and Toolkit Exercises"]},{"cell_type":"markdown","metadata":{"id":"mOeBlUrSfCpL"},"source":["# What is Machine Learning?\n","\n","| This | is   |\n","|------|------|\n","|   Machine learning allows computers to learn and infer from data.  | ![robot.png](Assets/robot.png)|\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y3UGuRZGfCpL"},"source":["# Learning Objectives\n","\n","- Demonstrate supervised learning algorithms\n","- Explain key concepts like under- and over-fitting, regularization, and cross-validation\n","- Classify the type of problem to be solved, choose the right algorithm, tune parameters, and validate a model\n","- Apply Intel® Extension for Scikit-learn* to leverage underlying compute capabilities of hardware"]},{"cell_type":"markdown","metadata":{"id":"AamCqR6cfCpL"},"source":["# Overview of Course:\n","\n","### Topics include:\n","\n","- Introduction and exploratory analysis (Week 1)\n","- Supervised machine learning (Weeks 2 – 10)\n","- Unsupervised machine learning (Weeks 11 – 12)\n","\n","### Prerequisites:\n","\n","- Python* programming\n","- Calculus\n","- Linear algebra\n","- Statistics\n","\n","### Lab Preparation:\n","- pip install -r ../requirements.txt\n","\n","### Our Toolset: Intel® oneAPI AI Analytics Toolkit (AI Kit)\n","- Intel® Extension for Scikit-learn*\n","\n","### Intel® oneAPI Toolkits Installation\n","The [following documents](https://software.intel.com/content/www/us/en/develop/articles/installation-guide-for-intel-oneapi-toolkits.html) provide detailed instructions on how to get and install Intel® oneAPI packages using different installer modes and package managers:\n","\n","- [Intel® oneAPI Toolkits Installation Guide for Linux* OS](https://software.intel.com/content/www/us/en/develop/documentation/installation-guide-for-intel-oneapi-toolkits-linux/top.html)\n","- [Intel® oneAPI Toolkits Installation Guide for Windows*](https://software.intel.com/content/www/us/en/develop/documentation/installation-guide-for-intel-oneapi-toolkits-windows/top.html)\n","- [Intel® oneAPI Toolkits Installation Guide for macOS*](https://software.intel.com/content/www/us/en/develop/documentation/installation-guide-for-intel-oneapi-toolkits-macos/top.html)\n","\n"]},{"cell_type":"markdown","metadata":{"run_control":{"marked":true},"id":"soB02gHCfCpM"},"source":["## Introduction\n","\n","We will be using the iris data set for this tutorial. This is a well-known data set containing iris species and sepal and petal measurements. The data we will use are in a file called `Iris_Data.csv` found in the [data](../../data) directory."]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2021-09-16T22:43:38.317839Z","start_time":"2021-09-16T22:43:38.311848Z"},"id":"r6RDaSi3fCpM","executionInfo":{"status":"ok","timestamp":1740980526977,"user_tz":-330,"elapsed":568,"user":{"displayName":"Rahul Bhati","userId":"05050286195702862122"}}},"outputs":[],"source":["from __future__ import print_function\n","import os\n","data_path = [\"C:\\\\Users\\\\Rahul\\\\Downloads\\\\Iris_Data.csv\"]"]},{"cell_type":"markdown","metadata":{"id":"jrzR9Du9fCpN"},"source":["\n","\n","# scikit-learn*\n","\n","Frameworks provide structure that Data Scientists use to build code. Frameworks are more than just libraries, because in addition to callable code, frameworks influence how code is written.\n","\n","A main virtue of using an optimized framework is that code runs faster. Code that runs faster is just generally more convenient but when we begin looking at applied data science and AI models, we can see more material benefits. Here you will see how optimization, particularly hyperparameter optimization can benefit more than just speed.\n","\n","These exercises will demonstrate how to apply **the Intel® Extension for Scikit-learn*,** a seamless way to speed up your Scikit-learn application. The acceleration is achieved through the use of the Intel® oneAPI Data Analytics Library (oneDAL). Patching is the term used to extend scikit-learn with Intel optimizations and makes it a well-suited machine learning framework for dealing with real-life problems.\n","\n","To get optimized versions of many Scikit-learn algorithms using a patch() approach consisting of adding these lines of code Prior to importing sklearn:\n","\n","- **from sklearnex import patch_sklearn**\n","- **patch_sklearn()**\n"]},{"cell_type":"markdown","metadata":{"run_control":{"marked":true},"id":"w4JqFYkVfCpN"},"source":["## Question 1\n","\n","Load the data from the file (data/Iris_Data.csv) using the techniques learned today. Examine it.\n","\n","Determine the following:\n","\n","* The number of data points (rows). (*Hint:* check out the dataframe `.shape` attribute.)\n","* The column names. (*Hint:* check out the dataframe `.columns` attribute.)\n","* The data types for each column. (*Hint:* check out the dataframe `.dtypes` attribute.)"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2017-03-19T23:17:21.954025Z","start_time":"2017-03-19T19:17:21.936220-04:00"},"run_control":{"marked":true},"id":"QiAQnVM2fCpO","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1740980682020,"user_tz":-330,"elapsed":879,"user":{"displayName":"Rahul Bhati","userId":"05050286195702862122"}},"outputId":"c99d2846-0fbf-4bff-a082-42874bbc22da"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rahul\\\\Downloads\\\\Iris_Data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-48cbd0c177d2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\\\Users\\\\Rahul\\\\Downloads\\\\Iris_Data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Number of data points (rows)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Rahul\\\\Downloads\\\\Iris_Data.csv'"]}],"source":["# prompt: The number of data points (rows). (Hint: check out the dataframe .shape attribute.)\n","# The column names. (Hint: check out the dataframe .columns attribute.)\n","# The data types for each column. (Hint: check out the dataframe .dtypes attribute.)\n","\n","import pandas as pd\n","\n","# Load the data\n","data = pd.read_csv(\"C:\\\\Users\\\\Rahul\\\\Downloads\\\\Iris_Data.csv\")\n","\n","# Number of data points (rows)\n","num_rows = data.shape[0]\n","print(f\"Number of data points: {num_rows}\")\n","\n","# Column names\n","column_names = data.columns.tolist()\n","print(f\"Column names: {column_names}\")\n","\n","# Data types for each column\n","data_types = data.dtypes\n","print(\"Data types for each column:\")\n","data_types\n"]},{"cell_type":"markdown","metadata":{"run_control":{"marked":true},"id":"oxekc_S9fCpO"},"source":["## Question 2\n","\n","Examine the species names and note that they all begin with 'Iris-'. Remove this portion of the name so the species name is shorter.\n","\n","*Hint:* there are multiple ways to do this, but you could use either the [string processing methods](http://pandas.pydata.org/pandas-docs/stable/text.html) or the [apply method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.apply.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2017-03-19T23:17:53.678316Z","start_time":"2017-03-19T19:17:53.660202-04:00"},"run_control":{"marked":true},"id":"yW32-2H4fCpO"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"run_control":{"marked":true},"id":"GCg9IIgPfCpO"},"source":["## Question 3\n","\n","Determine the following:  \n","* The number of each species present. (*Hint:* check out the series `.value_counts` method.)\n","* The mean, median, and quantiles and ranges (max-min) for each petal and sepal measurement.\n","\n","*Hint:* for the last question, the `.describe` method does have median, but it's not called median. It's the *50%* quantile. `.describe` does not have range though, and in order to get the range, you will need to create a new entry in the `.describe` table, which is `max - min`."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2017-03-19T23:20:16.483215Z","start_time":"2017-03-19T19:20:16.472865-04:00"},"run_control":{"marked":true},"id":"xkGrIrHFfCpO"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"run_control":{"marked":true},"id":"Bnfgl0ywfCpP"},"source":["## Question 4\n","\n","Calculate the following **for each species** in a separate dataframe:\n","\n","* The mean of each measurement (sepal_length, sepal_width, petal_length, and petal_width).\n","* The median of each of these measurements.\n","\n","*Hint:* you may want to use Pandas [`groupby` method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html) to group by species before calculating the statistic.\n","\n","If you finish both of these, try calculating both statistics (mean and median) in a single table (i.e. with a single groupby call). See the section of the Pandas documentation on [applying multiple functions at once](http://pandas.pydata.org/pandas-docs/stable/groupby.html#applying-multiple-functions-at-once) for a hint."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2017-03-19T23:22:07.306171Z","start_time":"2017-03-19T19:22:07.286965-04:00"},"id":"1anpAm_cfCpP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Ur8nj9TJfCpP"},"source":["## Question 5\n","\n","Make a scatter plot of `sepal_length` vs `sepal_width` using Matplotlib. Label the axes and give the plot a title."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2017-03-19T23:23:36.914375Z","start_time":"2017-03-19T19:23:36.661322-04:00"},"id":"ORDaO7n2fCpP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"kynJcMo6fCpP"},"source":["## Question 6\n","\n","Make a histogram of any one of the four features. Label axes and title it as appropriate."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Uz-eZXNfCpP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Ensnr2C2fCpP"},"source":["## Question 7\n","\n","Now create a single plot with histograms for each feature (`petal_width`, `petal_length`, `sepal_width`, `sepal_length`) overlayed. If you have time, next try to create four individual histogram plots in a single figure, where each plot contains one feature.\n","\n","For some hints on how to do this with Pandas plotting methods, check out the [visualization guide](http://pandas.pydata.org/pandas-docs/version/0.18.1/visualization.html) for Pandas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uk_O4KQzfCpP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"V8LJZyiCfCpQ"},"source":["## Question 8\n","\n","Using Pandas, make a boxplot of each petal and sepal measurement. Here is the documentation for [Pandas boxplot method](http://pandas.pydata.org/pandas-docs/version/0.18.1/visualization.html#visualization-box)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0jacVqMfCpQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"A7JscYe7fCpQ"},"source":["## Question 9\n","\n","Now make a single boxplot where the features are separated in the x-axis and species are colored with different hues.\n","\n","*Hint:* you may want to check the documentation for [Seaborn boxplots](http://seaborn.pydata.org/generated/seaborn.boxplot.html).\n","\n","Also note that Seaborn is very picky about data format--for this plot to work, the input dataframe will need to be manipulated so that each row contains a single data point (a species, a measurement type, and the measurement value). Check out Pandas [stack](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.stack.html) method as a starting place.\n","\n","Here is an example of a data format that will work:\n","\n","|   | species | measurement  | size |\n","| - | ------- | ------------ | ---- |\n","| 0\t| setosa  | sepal_length | 5.1  |\n","| 1\t| setosa  | sepal_width  | 3.5  |"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAOYGDe2fCpQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"u5ZbCjeVfCpQ"},"source":["## Question 10\n","\n","Make a [pairplot](http://seaborn.pydata.org/generated/seaborn.pairplot.html) with Seaborn to examine the correlation between each of the measurements.\n","\n","*Hint:* this plot may look complicated, but it is actually only a single line of code. This is the power of Seaborn and dataframe-aware plotting! See the lecture notes for reference."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wuEKJSwDfCpQ"},"outputs":[],"source":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[{"file_id":"1Yz2GAXPdUSpOVOoay8UPe20hB9BDUgiB","timestamp":1740980009212}]}},"nbformat":4,"nbformat_minor":0}